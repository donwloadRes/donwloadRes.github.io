---
layout: post
title: "基于CNN的花卉分类调参记录"
date:   2021-09-09
tags: [卷积,步数,识别率,CNN,ReLU]
comments: true
author: admin
---
# 基于CNN的花卉分类调参记录

本资源文件记录了基于卷积神经网络（CNN）对5类花卉植物数据进行分类的调参过程，逐步提升分类准确率。通过详细的调参记录，展示了如何通过数据增强、模型改进、自适应调整学习率等方法，逐步优化模型性能。

## 内容概述

1. **基本CNN模型**：
   - 卷积层1：32个卷积核，大小5x5，步数1，激活函数ReLU，最大池化，步数2，输入150x150x3
   - 卷积层2：64个卷积核，大小3x3，步数1，激活函数ReLU，最大池化，步数2
   - 卷积层3：96个卷积核，大小3x3，步数1，激活函数ReLU，最大池化，步数2
   - 卷积层4：96个卷积核，大小3x3，步数1，激活函数ReLU，最大池化，步数2
   - 全连接层1：512个神经元，激活函数ReLU
   - 全连接层2：256个神经元，激活函数ReLU
   - 分类层：5个神经元，激活函数softmax
   - batch_size=16，epoch=50
   - 效果：识别率在65%左右，出现过度拟合

2. **数据增强**：
   - 随机旋转范围10度，随机缩放0.9~1.1范围，水平和竖直偏移为范围0.2
   - epoch=50
   - 效果：识别率在77%左右，训练loss持续下降

3. **模型改进**：
   - 添加权重衰减、Dropout层、批正则化层（BN）
   - epoch=150
   - 效果：识别率在83%左右

4. **自调整学习率**：
   - 如果在5个epoch内验证识别率不增加，就让学习率变为原来的0.1倍
   - epoch=50，batch_size增加
   - 效果：识别率在85%左右

5. **增加CNN网络深度**：
   - 在每个卷积层后面重复同样数量的2个卷积层
   - 效果：识别率提升0.5%~1%

## 总结

- 卷积核尺寸不能超过图像尺寸，否则训练效果不佳。
- 过拟合时，采用合适的数据增强十分有效，水平翻转比竖直翻转更有效。
- 预处理阶段，让X_train归一化具有一定效果。
- BN层和Dropout层的效果尤为明显。
- 深度网络的理解能力优于非深度网络，但深度增加并不一定能显著提升性能。
- 学习率的选择非常重要，自适应调整学习率是一种很好的方法。

通过本资源文件，您可以学习到如何通过逐步调参优化CNN模型，提升花卉分类的准确率。

## 下载链接

[基于CNN的花卉分类调参记录](https://pan.quark.cn/s/d0e765e63e3a)