---
layout: post
title: "AI大模型：盘古大模型介绍"
date:   2022-05-09
tags: [模型,盘古,AI,Transformer,参数]
comments: true
author: admin
---
# AI大模型：盘古大模型介绍

## 资源文件描述

本资源文件详细介绍了AI大模型的演变历程，特别是盘古大模型的相关内容。大模型的起源可以追溯到2017年，当时随着Transformer结构的提出，深度学习模型的参数规模首次突破了1亿。从早期的Lenet、Alexnet、ResNet等模型开始，深度学习的神经网络模型参数逐渐增大。随后，BERT网络模型的提出使得参数量首次超过3亿规模。紧接着，GPT-3模型将参数量提升至百亿级别，而鹏程盘古模型则实现了千亿稠密的规模。最终，Switch Transformer的问世更是将模型参数规模一举突破万亿。

通过本资源文件，您将深入了解AI大模型的发展历程及其在技术上的重要突破，特别是盘古大模型在这一领域的重要地位和贡献。

## 下载链接

[AI大模型盘古大模型介绍](https://pan.quark.cn/s/1b531918ae9c)