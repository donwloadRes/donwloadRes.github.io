---
layout: post
title: "笔记本电脑部署本地离线版类似ChatGPT 3.5的AI模型(CPU+内存运行)"
date:   2022-12-10
tags: [模型,CPU,Vicuna,AI,13B]
comments: true
author: admin
---
# 笔记本电脑部署本地离线版类似ChatGPT 3.5的AI模型(CPU+内存运行)

欢迎使用本资源包，本指南将引导您在不具备高端GPU的笔记本电脑上，仅依赖CPU和内存，部署一个类似于ChatGPT 3.5功能的AI模型。此过程适合于希望在离线环境下运行大型语言模型的用户，尤其适合开发者和爱好者，无需昂贵的云计算资源。

## 准备工作

在开始之前，请确认您的笔记本电脑满足基本要求，并按照以下步骤准备：

1. **检查指令集**：确保您的CPU支持AVX512指令集，这将大幅提高模型运行速度。如果不支持，项目仍可运行，但速度较慢。
   
2. **下载必要的软件**：
   - **llama.cpp**: 支持CPU运行模型，特有AVX512版本优化，若需其他指令集，资源包内或社区有说明。
   - **模型文件**：推荐选用[Vicuna 13B](#)或[Alpaca 13B](#)，其中Vicuna被誉为接近ChatGPT 3.5性能的小羊驼模型，Alpaca来自斯坦福大学，也是强大之选。

## 模型下载

- **Vicuna 13B**: 微调自LLaMA，达到接近ChatGPT 3.5的对话质量，特别适合英文交互，中文表现亦不错。
- **Alpaca 13B**: 中文用户体验稍逊，但也是一个优秀的选择，特别是有中文扩展版本可供下载。

### 部署步骤

1. **创建项目目录**：比如命名为“AI”，在此目录下存放所有下载文件。
2. **放置模型文件**：将下载的模型文件放入项目目录中。
3. **配置批处理脚本**：创建`.bat`文件，编写启动命令，例如使用Vicuna模型的示例命令如下：
   ```
   main.exe --ctx_size 2048 --temp 0.7 --top_k 40 --top_p 0.5 ... --model "vicuna-13B-1.1-GPTQ-4bit-128g.ggml.bin"
   ```
   注意调整参数以适应您的硬件配置和需要。

4. **运行模型**：双击批处理文件开始运行，耐心等待模型初始化，随后便可以开始对话。

## 注意事项

- **性能提示**：由于依赖CPU，高内存消耗和较长的响应时间是常态，尤其是处理复杂或长篇对话时。
- **非商用许可**：Vicuna和Alpaca等模型不可用于商业用途，请遵守相关版权协议。
- **中文支持**：虽然未专为中文优化，Vicuna对中文的处理能力尚可，复杂对话建议使用英语以获得最佳效果。

通过遵循上述步骤，您就能在个人笔记本上享受离线的人工智能对话体验，无需网络，随时与您的AI助手进行互动。

---

此文档为您提供了一个简洁明了的部署指南，如果您遇到任何问题，建议参考原文档或加入相关开发者社区寻求帮助。祝您部署顺利！

## 下载链接

[笔记本电脑部署本地离线版类似ChatGPT3.5的AI模型CPU内存运行分享](https://pan.quark.cn/s/6f34850ef9ea)